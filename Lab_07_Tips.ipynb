{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basic Approach to Train Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd547da1930>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "x_train = torch.FloatTensor([[1, 2, 1],\n",
    "                             [1, 3, 2],\n",
    "                             [1, 3, 4],\n",
    "                             [1, 5, 5],\n",
    "                             [1, 7, 5],\n",
    "                             [1, 2, 5],\n",
    "                             [1, 6, 6],\n",
    "                             [1, 7, 7]\n",
    "                            ]) # (8, 3)\n",
    "y_train = torch.LongTensor([2, 2, 2, 1, 1, 1, 0, 0]) # (8, )\n",
    "\n",
    "# test set\n",
    "x_test = torch.FloatTensor([[2, 1, 1], [3, 1, 2], [3, 3, 4]]) # (3, 3)\n",
    "y_test = torch.LongTensor([2, 2, 2]) # (3, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 3)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, x_train, y_train):\n",
    "    nb_epochs = 20\n",
    "    for epoch in range(nb_epochs):\n",
    "        prediction = model(x_train)\n",
    "        cost = F.cross_entropy(prediction, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch {:4d} / {} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, optimizer, x_test, y_test):\n",
    "    prediction = model(x_test)\n",
    "    predicted_classes = prediction.max(1)[1]\n",
    "    correct_count = (predicted_classes == y_test).sum().item()\n",
    "    cost = F.cross_entropy(prediction, y_test)\n",
    "    \n",
    "    print('Accuracy: {}% Cost: {:.6f}'.format(\n",
    "        correct_count / len(y_test) * 100, cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0 / 20 Cost: 2.203667\n",
      "Epoch    1 / 20 Cost: 1.199645\n",
      "Epoch    2 / 20 Cost: 1.142985\n",
      "Epoch    3 / 20 Cost: 1.117769\n",
      "Epoch    4 / 20 Cost: 1.100901\n",
      "Epoch    5 / 20 Cost: 1.089523\n",
      "Epoch    6 / 20 Cost: 1.079872\n",
      "Epoch    7 / 20 Cost: 1.071320\n",
      "Epoch    8 / 20 Cost: 1.063325\n",
      "Epoch    9 / 20 Cost: 1.055720\n",
      "Epoch   10 / 20 Cost: 1.048378\n",
      "Epoch   11 / 20 Cost: 1.041245\n",
      "Epoch   12 / 20 Cost: 1.034285\n",
      "Epoch   13 / 20 Cost: 1.027478\n",
      "Epoch   14 / 20 Cost: 1.020813\n",
      "Epoch   15 / 20 Cost: 1.014279\n",
      "Epoch   16 / 20 Cost: 1.007872\n",
      "Epoch   17 / 20 Cost: 1.001586\n",
      "Epoch   18 / 20 Cost: 0.995419\n",
      "Epoch   19 / 20 Cost: 0.989365\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0% Cost: 1.425844\n"
     ]
    }
   ],
   "source": [
    "test(model, optimizer, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "mnist_train = dsets.MNIST(root=\"MNIST_data/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = dsets.MNIST(root=\"MNIST_data/\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Training with Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 cost = 0.533512473\n",
      "Epoch:  0002 cost = 0.358718395\n",
      "Epoch:  0003 cost = 0.330776662\n",
      "Epoch:  0004 cost = 0.316283911\n",
      "Epoch:  0005 cost = 0.306691468\n",
      "Epoch:  0006 cost = 0.300063848\n",
      "Epoch:  0007 cost = 0.294828326\n",
      "Epoch:  0008 cost = 0.290769190\n",
      "Epoch:  0009 cost = 0.287165016\n",
      "Epoch:  0010 cost = 0.284340948\n",
      "Epoch:  0011 cost = 0.281696588\n",
      "Epoch:  0012 cost = 0.279585570\n",
      "Epoch:  0013 cost = 0.277511060\n",
      "Epoch:  0014 cost = 0.275934726\n",
      "Epoch:  0015 cost = 0.274179101\n",
      "Learning Finished\n"
     ]
    }
   ],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "linear = torch.nn.Linear(784, 10, bias=True)\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss() # softmax is internally computed\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "    \n",
    "    for X, Y in data_loader:\n",
    "    \t# reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28)\n",
    "        # GPU 쓸 경우\n",
    "        # Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost += cost / total_batch\n",
    "    \n",
    "    print(\"Epoch: \", \"%04d\" % (epoch+1), \"cost =\", \"{:.9f}\".format(avg_cost))\n",
    "print('Learning Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8833000063896179\n",
      "Label:  1\n",
      "Prediction:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjuke/opt/anaconda3/envs/DataMining/lib/python3.7/site-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/Users/jjuke/opt/anaconda3/envs/DataMining/lib/python3.7/site-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float()\n",
    "    Y_test = mnist_test.test_labels\n",
    "    \n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy: ', accuracy.item())\n",
    "    \n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float()\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1]\n",
    "    \n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5a8676ad23f3cc58145972a0c336e77f714f09ac46243a3533a887d514f360b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('DataMining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
